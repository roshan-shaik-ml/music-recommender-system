{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "yq_d2JPtCKDF"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import ollama\n",
        "import requests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_path = \"data\"\n",
        "current_part = \"pickle_part_9.pkl\"\n",
        "current_pickle_file = os.path.join(data_path, current_part)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PgfL2qsPEvDE"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# Đọc và gộp dữ liệu từ tất cả file .pkl - # Read and merge data from all .pkl files\n",
        "df = pd.read_pickle(os.path.join(current_pickle_file))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.iloc[1, :]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zhlhx-8WFZ6P"
      },
      "outputs": [],
      "source": [
        "# Convert them to lyrics - Chuyển đổi chúng thành lời bài hát\n",
        "def convert_to_lyrics(df):\n",
        "    df['lyrics'] = df['text'].apply(lambda x: x.replace('\\n', ' ').strip())\n",
        "    return df[['id', 'lyrics']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UqnZGGXLFflj"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "\n",
        "OLLAMA_HOST = \"http://localhost:11434\"\n",
        "\n",
        "def generate_response(model: str = \"nomic-embed-text\", prompt: str = \"The sky is blue because of Rayleigh scattering\"):\n",
        "    url = f\"{OLLAMA_HOST}/api/embeddings\"\n",
        "    payload = {\n",
        "        \"model\": model,\n",
        "        \"prompt\": prompt,\n",
        "        \"stream\": False  # Set to True if you want streaming\n",
        "    }\n",
        "\n",
        "    response = requests.post(url, json=payload)\n",
        "    response.raise_for_status()  # Throw if error\n",
        "    try:\n",
        "        return response.json().get(\"embedding\")\n",
        "    except Exception as e:\n",
        "        return response.text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1xSDQAJpN9is",
        "outputId": "ceebeddd-8998-420e-a159-66ba01046335"
      },
      "outputs": [],
      "source": [
        "import logging\n",
        "import time\n",
        "# Configure logging to a file with timestamps, create in the current directory\n",
        "logging_file_name = f\"embedding_log_{time.strftime('%Y%m%d_%H%M%S')}.log\"\n",
        "logging.basicConfig(filename=logging_file_name, level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for i, lyric in enumerate(lyrics[0:100]):\n",
        "    try:\n",
        "        logging.info(f\"Processing lyric index: {i}\")\n",
        "        embeddings = generate_response(prompt=lyric)\n",
        "        print(f\"Generated embeddings for lyric index {i}: {embeddings}\")\n",
        "        logging.info(f\"Generated embeddings for lyric index {i}\")\n",
        "        # Chroma Database integration would go here\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error processing lyric index {i}: {e}\")\n",
        "        logging.warning(f\"Skipping lyric index {i} with lyrics: {lyrics}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import requests\n",
        "import chromadb\n",
        "import logging\n",
        "import time\n",
        "\n",
        "\n",
        "chroma_db_path = r\"D:\\ĐỒ ÁN TỐT NGHIỆP\\all_pickles\\chroma_db\"\n",
        "\n",
        "\n",
        "chroma_client = chromadb.PersistentClient(path=chroma_db_path)\n",
        "collection = chroma_client.get_or_create_collection(name=\"lyrics_embeddings\")\n",
        "\n",
        "# Logging\n",
        "logging_file_name = f\"embedding_log_{time.strftime('%Y%m%d_%H%M%S')}.log\"\n",
        "logging.basicConfig(filename=logging_file_name, level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "\n",
        "# URL OLLAMA\n",
        "OLLAMA_HOST = \"http://localhost:11434\"\n",
        "\n",
        "def generate_response(model: str = \"nomic-embed-text\", prompt: str = \"The sky is blue because of Rayleigh scattering\"):\n",
        "    url = f\"{OLLAMA_HOST}/api/embeddings\"\n",
        "    payload = {\n",
        "        \"model\": model,\n",
        "        \"prompt\": prompt,\n",
        "        \"stream\": False\n",
        "    }\n",
        "\n",
        "    response = requests.post(url, json=payload)\n",
        "    response.raise_for_status()\n",
        "    try:\n",
        "        return response.json().get(\"embedding\")\n",
        "    except:\n",
        "        return response.text\n",
        "\n",
        "# Đường dẫn thư mục chứa các file .pkl\n",
        "data_folder = r\"D:\\ĐỒ ÁN TỐT NGHIỆP\\all_pickles\\data\"\n",
        "\n",
        "# Biến đếm tổng embeddings\n",
        "embedding_count = 0\n",
        "\n",
        "# Duyệt toàn bộ file .pkl trong thư mục\n",
        "for file_name in os.listdir(data_folder):\n",
        "    if file_name.endswith(\".pkl\"):\n",
        "        file_path = os.path.join(data_folder, file_name)\n",
        "        logging.info(f\"Processing file: {file_name}\")\n",
        "\n",
        "        # Đọc DataFrame từ file .pkl\n",
        "        df = pd.read_pickle(file_path)\n",
        " \n",
        "        # Lấy danh sách lyrics\n",
        "        lyrics = df['lyrics'].dropna().tolist()\n",
        "\n",
        "        for i, lyric in enumerate(lyrics):\n",
        "            try:\n",
        "                logging.info(f\"Processing lyric index {i} in file {file_name}\")\n",
        "                embedding = generate_response(prompt=lyric)\n",
        "\n",
        "                # Lưu vào ChromaDB persistent\n",
        "                collection.add(\n",
        "                    ids=[f\"{file_name}_{i}\"],\n",
        "                    documents=[lyric],\n",
        "                    embeddings=[embedding]\n",
        "                )\n",
        "\n",
        "                embedding_count += 1\n",
        "                logging.info(f\"Generated and saved embedding for index {i} in file {file_name}\")\n",
        "\n",
        "            except Exception as e:\n",
        "                logging.error(f\"Error processing lyric index {i} in file {file_name}: {e}\")\n",
        "                logging.warning(f\"Skipping lyric index {i} in file {file_name}\")\n",
        "\n",
        "print(f\"✅ Migrated to new architecture and saved {embedding_count} embeddings vào ChromaDB!\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
